"use strict";(self.webpackChunkvibhavari_bellutagi=self.webpackChunkvibhavari_bellutagi||[]).push([[9226],{7992:(e,a,t)=>{t.r(a),t.d(a,{assets:()=>c,contentTitle:()=>r,default:()=>d,frontMatter:()=>n,metadata:()=>s,toc:()=>p});var s=t(4604),i=t(4848),o=t(8453);t(4512),t(552),t(1807),t(3760);const n={slug:"spark-execution-modes",title:"Spark Execution Modes",authors:["me"],tags:["de","apache-spark"],keywords:["data engineering","apache spark","spark application architecture","spark execution modes"],hide_table_of_contents:!1},r=void 0,c={authorsImageUrls:[void 0]},p=[];function l(e){const a={p:"p",...(0,o.R)(),...e.components};return(0,i.jsx)(a.p,{children:"In this post, we will discuss the different execution modes available in Apache Spark. Apache Spark provides three execution modes to run Spark applications. These execution modes are: Cluster mode, Client mode, and Local mode. Each of these modes has its own use case and is suitable for different scenarios."})}function d(e={}){const{wrapper:a}={...(0,o.R)(),...e.components};return a?(0,i.jsx)(a,{...e,children:(0,i.jsx)(l,{...e})}):l(e)}},3760:(e,a,t)=>{t.d(a,{A:()=>s});const s=t.p+"assets/images/client_mode-425a36cd961a4be2fddf5ef5536c5f84.gif"},552:(e,a,t)=>{t.d(a,{A:()=>s});const s=t.p+"assets/images/cluster_manager-ee69ff7b4553bc54b04ae088f7250cf9.png"},1807:(e,a,t)=>{t.d(a,{A:()=>s});const s=t.p+"assets/images/cluster_mode-e0aa25aea4b420a85c48b967f0b1e514.gif"},4604:e=>{e.exports=JSON.parse('{"permalink":"/blog/spark-execution-modes","source":"@site/blog/2025-02-06-spark-execution-modes/index.md","title":"Spark Execution Modes","description":"In this post, we will discuss the different execution modes available in Apache Spark. Apache Spark provides three execution modes to run Spark applications. These execution modes are: Cluster mode, Client mode, and Local mode. Each of these modes has its own use case and is suitable for different scenarios.","date":"2025-02-06T00:00:00.000Z","tags":[{"inline":false,"label":"data-engineering","permalink":"/blog/tags/de","description":"DE tag description"},{"inline":false,"label":"apache-spark","permalink":"/blog/tags/apache-spark","description":"Spark tag description"}],"readingTime":3.975,"hasTruncateMarker":true,"authors":[{"name":"Vibhavari Bellutagi","title":"Data Engineer","url":"https://buildwithvibs.in/","socials":{"github":"https://github.com/vibhabellutagi19","linkedin":"https://www.linkedin.com/in/vibhavari-bellutagi-837871189/","twitter":"https://twitter.com/buildwith_vibs"},"imageURL":"https://avatars.githubusercontent.com/u/39341524?s=400&u=5d760c052fe0614d3af649de9e85474d1cafeba7&v=4","key":"me","page":null}],"frontMatter":{"slug":"spark-execution-modes","title":"Spark Execution Modes","authors":["me"],"tags":["de","apache-spark"],"keywords":["data engineering","apache spark","spark application architecture","spark execution modes"],"hide_table_of_contents":false},"unlisted":false,"prevItem":{"title":"The Life Cycle of a Spark Application ( Outside )","permalink":"/blog/spark-application-lifecycle-outside"},"nextItem":{"title":"Under the hood of a Spark job","permalink":"/blog/spark-job-anatomy"}}')}}]);